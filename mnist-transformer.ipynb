{"cells":[{"cell_type":"markdown","metadata":{},"source":["# **Version 1.0**"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-06-06T09:41:09.154535Z","iopub.status.busy":"2024-06-06T09:41:09.153678Z","iopub.status.idle":"2024-06-06T09:43:21.250522Z","shell.execute_reply":"2024-06-06T09:43:21.248881Z","shell.execute_reply.started":"2024-06-06T09:41:09.154497Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - accuracy: 0.4627 - loss: 1.5387 - val_accuracy: 0.8862 - val_loss: 0.3791\n","Epoch 2/10\n","\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 17ms/step - accuracy: 0.8580 - loss: 0.4524 - val_accuracy: 0.9276 - val_loss: 0.2332\n","Epoch 3/10\n","\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.9060 - loss: 0.3099 - val_accuracy: 0.9423 - val_loss: 0.1862\n","Epoch 4/10\n","\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.9214 - loss: 0.2548 - val_accuracy: 0.9437 - val_loss: 0.1848\n","Epoch 5/10\n","\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.9302 - loss: 0.2318 - val_accuracy: 0.9474 - val_loss: 0.1697\n","Epoch 6/10\n","\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.9384 - loss: 0.2062 - val_accuracy: 0.9567 - val_loss: 0.1453\n","Epoch 7/10\n","\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.9411 - loss: 0.1933 - val_accuracy: 0.9601 - val_loss: 0.1328\n","Epoch 8/10\n","\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.9475 - loss: 0.1745 - val_accuracy: 0.9610 - val_loss: 0.1271\n","Epoch 9/10\n","\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9484 - loss: 0.1709 - val_accuracy: 0.9637 - val_loss: 0.1248\n","Epoch 10/10\n","\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9526 - loss: 0.1571 - val_accuracy: 0.9625 - val_loss: 0.1266\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9552 - loss: 0.1315\n","Test accuracy: 0.9610999822616577\n"]}],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras import layers, models\n","\n","# Load MNIST data from the local mnist.npz file\n","with np.load('/kaggle/input/mnist-dataset/mnist.npz') as data:\n","    x_train, y_train = data['x_train'], data['y_train']\n","    x_test, y_test = data['x_test'], data['y_test']\n","\n","x_train = x_train.astype('float32') / 255.0\n","x_test = x_test.astype('float32') / 255.0\n","\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","\n","x_train = x_train.reshape((-1, 28, 28))\n","x_test = x_test.reshape((-1, 28, 28))\n","\n","# Define transformer components\n","class TransformerBlock(layers.Layer):\n","    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n","        super(TransformerBlock, self).__init__()\n","        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n","        self.ffn = models.Sequential(\n","            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim)]\n","        )\n","        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n","        self.dropout1 = layers.Dropout(rate)\n","        self.dropout2 = layers.Dropout(rate)\n","\n","    def call(self, inputs, training):\n","        attn_output = self.att(inputs, inputs)\n","        attn_output = self.dropout1(attn_output, training=training)\n","        out1 = self.layernorm1(inputs + attn_output)\n","        ffn_output = self.ffn(out1)\n","        ffn_output = self.dropout2(ffn_output, training=training)\n","        return self.layernorm2(out1 + ffn_output)\n","\n","class TokenAndPositionEmbedding(layers.Layer):\n","    def __init__(self, maxlen, embed_dim):\n","        super(TokenAndPositionEmbedding, self).__init__()\n","        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n","        self.token_emb = layers.Dense(embed_dim)\n","        self.maxlen = maxlen\n","\n","    def call(self, x):\n","        positions = tf.range(start=0, limit=self.maxlen, delta=1)\n","        positions = self.pos_emb(positions)\n","        x = self.token_emb(x)\n","        return x + positions\n","\n","def create_transformer_model(maxlen=28, embed_dim=32, num_heads=2, ff_dim=32):\n","    inputs = layers.Input(shape=(maxlen, 28))\n","    embedding_layer = TokenAndPositionEmbedding(maxlen, embed_dim)\n","    x = embedding_layer(inputs)\n","    transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n","    x = transformer_block(x, training=True)  # Pass the training argument here\n","    x = layers.GlobalAveragePooling1D()(x)\n","    x = layers.Dropout(0.1)(x)\n","    x = layers.Dense(20, activation=\"relu\")(x)\n","    x = layers.Dropout(0.1)(x)\n","    outputs = layers.Dense(10, activation=\"softmax\")(x)\n","    model = models.Model(inputs=inputs, outputs=outputs)\n","    return model\n","\n","model = create_transformer_model()\n","model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n","\n","# Train the model\n","model.fit(x_train, y_train, batch_size=64, epochs=10, validation_split=0.2)\n","\n","# Evaluate the model\n","test_loss, test_acc = model.evaluate(x_test, y_test)\n","print(f'Test accuracy: {test_acc}')\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5161036,"sourceId":8621618,"sourceType":"datasetVersion"}],"dockerImageVersionId":30732,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
